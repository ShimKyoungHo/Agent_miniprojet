# agents/consumer_analysis_agent.py

from typing import Dict, Any, Optional, List
import asyncio
import os
from datetime import datetime
from tavily import TavilyClient
from .base_agent import BaseAgent


class ConsumerAnalysisAgent(BaseAgent):
    """ì†Œë¹„ì ë¶„ì„ Agent - Tavily ì›¹ ê²€ìƒ‰ í™œìš©"""
    
    def __init__(self, llm=None, config: Optional[Dict] = None):
        super().__init__("consumer_analysis", llm, config)
        
        # Tavily í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        tavily_api_key = os.getenv('TAVILY_API_KEY')
        if tavily_api_key:
            self.tavily_client = TavilyClient(api_key=tavily_api_key)
            self.logger.info("Tavily í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            self.tavily_client = None
            self.logger.warning("TAVILY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
    
    async def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ì†Œë¹„ì ë¶„ì„ ë©”ì¸ í”„ë¡œì„¸ìŠ¤"""
        self.logger.info("ì†Œë¹„ì ë¶„ì„ ì‹œì‘...")
        
        # Market Research ë°ì´í„° í™•ì¸
        market_data = state.get('market_data', {})
        market_trends = state.get('market_trends', {})
        
        try:
            # ë³‘ë ¬ë¡œ ì†Œë¹„ì ë°ì´í„° ìˆ˜ì§‘
            tasks = [
                self._analyze_purchase_factors(),
                self._analyze_consumer_demographics(),
                self._analyze_price_sensitivity(),
                self._analyze_brand_preferences(),
                self._analyze_adoption_barriers(),
                self._analyze_consumer_sentiment(),
                self._analyze_vehicle_type_preferences()
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ í†µí•©
            consumer_data = {
                'purchase_factors': results[0] if not isinstance(results[0], Exception) else None,
                'demographics': results[1] if not isinstance(results[1], Exception) else None,
                'price_sensitivity': results[2] if not isinstance(results[2], Exception) else None,
                'brand_preferences': results[3] if not isinstance(results[3], Exception) else None,
                'adoption_barriers': results[4] if not isinstance(results[4], Exception) else None,
                'consumer_sentiment': results[5] if not isinstance(results[5], Exception) else None,
                'vehicle_preferences': results[6] if not isinstance(results[6], Exception) else None,
                'timestamp': self.get_timestamp()
            }
            
            # preferences êµ¬ì¡° ì¶”ê°€ (ì°¨íŠ¸ í˜¸í™˜ì„±)
            if consumer_data['vehicle_preferences']:
                consumer_data['preferences'] = {
                    'vehicle_type': consumer_data['vehicle_preferences'].get('vehicle_type', {})
                }
            
            # ì˜í–¥ ê°€ì¤‘ì¹˜ ê³„ì‚°
            weights = await self._calculate_influence_weights(consumer_data)
            consumer_data['influence_weights'] = weights
            
            # ì‹œì¥ ë°ì´í„°ì™€ í†µí•© ë¶„ì„
            integrated_analysis = await self._integrate_with_market_data(
                consumer_data, market_data, market_trends
            )
            consumer_data['integrated_analysis'] = integrated_analysis
            
            # LLM ì¢…í•© ë¶„ì„
            if self.llm:
                synthesis = await self._synthesize_consumer_insights(consumer_data)
                consumer_data['synthesis'] = synthesis
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            state['consumer_patterns'] = consumer_data
            
            # ê²°ê³¼ ì €ì¥
            self.save_output(consumer_data, 'consumer_analysis.json')
            
            self.logger.info("âœ… ì†Œë¹„ì ë¶„ì„ ì™„ë£Œ")
            return state
            
        except Exception as e:
            self.logger.error(f"ì†Œë¹„ì ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            state['errors'].append(f"consumer_analysis: {str(e)}")
            return state
    
    async def _analyze_purchase_factors(self) -> Dict:
        """êµ¬ë§¤ ê²°ì • ìš”ì¸ ë¶„ì„"""
        self.logger.info("  ğŸ›’ êµ¬ë§¤ ê²°ì • ìš”ì¸ ë¶„ì„ ì¤‘...")
        
        if not self.tavily_client:
            return self._get_fallback_purchase_factors()
        
        try:
            query = "electric vehicle purchase decision factors consumer survey 2025"
            search_results = await asyncio.to_thread(
                self.tavily_client.search,
                query=query,
                max_results=5
            )
            
            # ì¶”ê°€ ê²€ìƒ‰: êµ¬ë§¤ ì¥ë²½
            query2 = "why consumers buy electric vehicles main reasons"
            search_results2 = await asyncio.to_thread(
                self.tavily_client.search,
                query=query2,
                max_results=3
            )
            
            return {
                'main_query': {
                    'query': query,
                    'results': search_results.get('results', [])
                },
                'secondary_query': {
                    'query': query2,
                    'results': search_results2.get('results', [])
                },
                'analysis_date': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"êµ¬ë§¤ ìš”ì¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_purchase_factors()
    
    async def _analyze_consumer_demographics(self) -> Dict:
        """ì†Œë¹„ì ì¸êµ¬í†µê³„ ë¶„ì„"""
        self.logger.info("  ğŸ‘¥ ì†Œë¹„ì ì¸êµ¬í†µê³„ ë¶„ì„ ì¤‘...")
        
        if not self.tavily_client:
            return self._get_fallback_demographics()
        
        try:
            queries = [
                "electric vehicle buyer demographics age income 2025",
                "EV adoption by generation millennials gen z statistics",
                "electric vehicle ownership by region urban rural"
            ]
            
            results = []
            for query in queries:
                search_results = await asyncio.to_thread(
                    self.tavily_client.search,
                    query=query,
                    max_results=3
                )
                results.append({
                    'query': query,
                    'results': search_results.get('results', [])
                })
            
            return {
                'demographic_searches': results,
                'analysis_date': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ì¸êµ¬í†µê³„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_demographics()
    
    async def _analyze_price_sensitivity(self) -> Dict:
        """ê°€ê²© ë¯¼ê°ë„ ë¶„ì„"""
        self.logger.info("  ğŸ’° ê°€ê²© ë¯¼ê°ë„ ë¶„ì„ ì¤‘...")
        
        if not self.tavily_client:
            return self._get_fallback_price_sensitivity()
        
        try:
            query = "electric vehicle price sensitivity consumer willingness to pay 2025"
            search_results = await asyncio.to_thread(
                self.tavily_client.search,
                query=query,
                max_results=5
            )
            
            # ì¶”ê°€: ê°€ê²© ëŒ€ë¹„ ê°€ì¹˜
            query2 = "electric vehicle total cost ownership vs gasoline"
            search_results2 = await asyncio.to_thread(
                self.tavily_client.search,
                query=query2,
                max_results=3
            )
            
            return {
                'price_sensitivity': {
                    'query': query,
                    'results': search_results.get('results', [])
                },
                'value_comparison': {
                    'query': query2,
                    'results': search_results2.get('results', [])
                },
                'analysis_date': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ê°€ê²© ë¯¼ê°ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_price_sensitivity()
    
    async def _analyze_brand_preferences(self) -> Dict:
        """ë¸Œëœë“œ ì„ í˜¸ë„ ë¶„ì„"""
        self.logger.info("  ğŸ·ï¸ ë¸Œëœë“œ ì„ í˜¸ë„ ë¶„ì„ ì¤‘...")
        
        if not self.tavily_client:
            return self._get_fallback_brand_preferences()
        
        try:
            query = "electric vehicle brand preference consumer survey loyalty 2025"
            search_results = await asyncio.to_thread(
                self.tavily_client.search,
                query=query,
                max_results=5
            )
            
            return {
                'query': query,
                'results': search_results.get('results', []),
                'analysis_date': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ë¸Œëœë“œ ì„ í˜¸ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_brand_preferences()
    
    async def _analyze_adoption_barriers(self) -> Dict:
        """ë„ì… ì¥ë²½ ë¶„ì„"""
        self.logger.info("  ğŸš§ ë„ì… ì¥ë²½ ë¶„ì„ ì¤‘...")
        
        if not self.tavily_client:
            return self._get_fallback_adoption_barriers()
        
        try:
            queries = [
                "electric vehicle adoption barriers challenges 2025",
                "EV charging infrastructure concerns consumer",
                "electric vehicle range anxiety statistics"
            ]
            
            results = []
            for query in queries:
                search_results = await asyncio.to_thread(
                    self.tavily_client.search,
                    query=query,
                    max_results=3
                )
                results.append({
                    'query': query,
                    'results': search_results.get('results', [])
                })
            
            return {
                'barrier_searches': results,
                'analysis_date': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ë„ì… ì¥ë²½ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_adoption_barriers()
    
    async def _analyze_vehicle_type_preferences(self) -> Dict:
        """ì°¨ëŸ‰ íƒ€ì… ì„ í˜¸ë„ ë¶„ì„ - ìƒˆë¡œìš´ í•¨ìˆ˜"""
        self.logger.info("  ğŸš— ì°¨ëŸ‰ íƒ€ì… ì„ í˜¸ë„ ë¶„ì„ ì¤‘...")
        
        if not self.tavily_client:
            return self._get_fallback_vehicle_preferences()
        
        try:
            query = "electric vehicle type preferences SUV sedan truck consumer survey 2024"
            search_results = await asyncio.to_thread(
                self.tavily_client.search,
                query=query,
                max_results=5
            )
            
            # LLMìœ¼ë¡œ ë¶„ì„
            if self.llm and search_results.get('results'):
                analysis = await self._analyze_vehicle_preferences_with_llm(search_results)
                return {
                    'search_results': search_results.get('results', []),
                    'vehicle_type': analysis.get('vehicle_type', {}),
                    'llm_analysis': analysis.get('summary', ''),
                    'analysis_date': datetime.now().isoformat()
                }
            else:
                return self._get_fallback_vehicle_preferences()
            
        except Exception as e:
            self.logger.error(f"ì°¨ëŸ‰ íƒ€ì… ì„ í˜¸ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_vehicle_preferences()
    
    async def _analyze_vehicle_preferences_with_llm(self, search_results: Dict) -> Dict:
        """LLMìœ¼ë¡œ ì°¨ëŸ‰ íƒ€ì… ì„ í˜¸ë„ ë¶„ì„"""
        
        context = "\n\n".join([
            f"Source {i+1}: {r.get('content', '')[:500]}"
            for i, r in enumerate(search_results.get('results', [])[:3])
        ])
        
        prompt = f"""Based on the following search results about electric vehicle preferences, 
analyze consumer preferences by vehicle type.

{context}

Provide your analysis in JSON format:
{{
    "vehicle_type": {{
        "SUV": 0.35,
        "Sedan": 0.30,
        "Truck": 0.20,
        "Compact": 0.15
    }},
    "summary": "Brief summary of findings"
}}

The values should be proportions (0-1) that sum to 1.0.
"""
        
        try:
            response = await self.llm.ainvoke(prompt)
            
            # JSON íŒŒì‹±
            import json
            import re
            
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            json_match = re.search(r'\{.*\}', response.content, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return result
            else:
                return self._get_fallback_vehicle_preferences()
                
        except Exception as e:
            self.logger.error(f"LLM ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_vehicle_preferences()
    
    def _get_fallback_vehicle_preferences(self) -> Dict:
        """ì°¨ëŸ‰ íƒ€ì… ì„ í˜¸ë„ ê¸°ë³¸ê°’"""
        return {
            'vehicle_type': {
                'SUV': 0.35,
                'Sedan': 0.30,
                'Truck': 0.20,
                'Compact': 0.15
            },
            'search_results': [],
            'llm_analysis': 'ê¸°ë³¸ ë°ì´í„° ì‚¬ìš© (ê²€ìƒ‰ ì‹¤íŒ¨)',
            'analysis_date': datetime.now().isoformat()
        }
    
    async def _analyze_consumer_sentiment(self) -> Dict:
        """ì†Œë¹„ì ê°ì„± ë¶„ì„"""
        self.logger.info("  ğŸ˜Š ì†Œë¹„ì ê°ì„± ë¶„ì„ ì¤‘...")
        
        if not self.tavily_client:
            return self._get_fallback_consumer_sentiment()
        
        try:
            query = "electric vehicle consumer sentiment satisfaction reviews 2025"
            search_results = await asyncio.to_thread(
                self.tavily_client.search,
                query=query,
                max_results=5
            )
            
            return {
                'query': query,
                'results': search_results.get('results', []),
                'analysis_date': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ì†Œë¹„ì ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_consumer_sentiment()
    
    async def _calculate_influence_weights(self, consumer_data: Dict) -> Dict:
        """ì˜í–¥ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        self.logger.info("  âš–ï¸ ì˜í–¥ ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...")
        
        if not self.llm:
            return self._get_default_weights()
        
        try:
            # ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¶”ì¶œ ìš”ì²­
            prompt = """ì „ê¸°ì°¨ êµ¬ë§¤ ê²°ì •ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì£¼ìš” ìš”ì¸ë“¤ì˜ ìƒëŒ€ì  ê°€ì¤‘ì¹˜ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

ì£¼ìš” ìš”ì¸:
1. ê°€ê²© (Price)
2. ì£¼í–‰ê±°ë¦¬ (Range)
3. ì¶©ì „ ì¸í”„ë¼ (Charging Infrastructure)
4. ë¸Œëœë“œ ì‹ ë¢°ë„ (Brand Trust)
5. í™˜ê²½ ì˜ì‹ (Environmental Concern)
6. ì •ë¶€ ë³´ì¡°ê¸ˆ (Government Incentives)
7. ìš´ì˜ ë¹„ìš© (Operating Cost)
8. ì„±ëŠ¥/ê¸°ìˆ  (Performance/Technology)

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš” (í•©ê³„ 100%):
{
  "price": x,
  "range": x,
  "charging_infrastructure": x,
  "brand_trust": x,
  "environmental_concern": x,
  "government_incentives": x,
  "operating_cost": x,
  "performance_technology": x
}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
            
            response = await self.llm.ainvoke(prompt)
            content = response.content if hasattr(response, 'content') else str(response)
            
            # JSON íŒŒì‹± ì‹œë„
            import json
            import re
            
            # JSON ì¶”ì¶œ
            json_match = re.search(r'\{[^}]+\}', content, re.DOTALL)
            if json_match:
                weights = json.loads(json_match.group())
                self.logger.info(f"ì˜í–¥ ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ: {weights}")
                return weights
            else:
                return self._get_default_weights()
            
        except Exception as e:
            self.logger.error(f"ê°€ì¤‘ì¹˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return self._get_default_weights()
    
    def _get_default_weights(self) -> Dict:
        """ê¸°ë³¸ ê°€ì¤‘ì¹˜"""
        return {
            "price": 25,
            "range": 20,
            "charging_infrastructure": 15,
            "brand_trust": 12,
            "environmental_concern": 10,
            "government_incentives": 8,
            "operating_cost": 6,
            "performance_technology": 4
        }
    
    async def _integrate_with_market_data(self, consumer_data: Dict, market_data: Dict, market_trends: Dict) -> str:
        """ì‹œì¥ ë°ì´í„°ì™€ ì†Œë¹„ì ë°ì´í„° í†µí•© ë¶„ì„"""
        if not self.llm:
            return "í†µí•© ë¶„ì„ ë¶ˆê°€ (LLM ë¯¸ì„¤ì •)"
        
        try:
            prompt = f"""ì‹œì¥ ë°ì´í„°ì™€ ì†Œë¹„ì ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ì„¸ìš”:

ì‹œì¥ íŠ¸ë Œë“œ:
- ì „ê¸°ì°¨ ì‹œì¥ ì„±ì¥ë¥ : ì—°í‰ê·  18-22%
- ì£¼ìš” ì‹œì¥: ì¤‘êµ­, ìœ ëŸ½, ë¯¸êµ­

ì†Œë¹„ì ì˜í–¥ ê°€ì¤‘ì¹˜:
{consumer_data.get('influence_weights', self._get_default_weights())}

ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:
1. ì‹œì¥ ì„±ì¥ê³¼ ì†Œë¹„ì ìˆ˜ìš”ê°€ ì¼ì¹˜í•˜ëŠ”ê°€? (2-3ë¬¸ì¥)
2. ì†Œë¹„ìì˜ ì£¼ìš” ê´€ì‹¬ì‚¬ê°€ ì‹œì¥ íŠ¸ë Œë“œì— ë°˜ì˜ë˜ê³  ìˆëŠ”ê°€? (2-3ë¬¸ì¥)
3. í–¥í›„ 6-12ê°œì›” ì†Œë¹„ì ìˆ˜ìš” ì˜ˆì¸¡ (3-4ë¬¸ì¥)
"""
            
            response = await self.llm.ainvoke(prompt)
            return response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            self.logger.error(f"í†µí•© ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "í†µí•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
    
    async def _synthesize_consumer_insights(self, consumer_data: Dict) -> str:
        """ì†Œë¹„ì ë¶„ì„ ì¢…í•©"""
        if not self.llm:
            return "ì¢…í•© ë¶„ì„ ë¶ˆê°€ (LLM ë¯¸ì„¤ì •)"
        
        try:
            weights = consumer_data.get('influence_weights', self._get_default_weights())
            
            prompt = f"""ì „ê¸°ì°¨ ì†Œë¹„ì ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì„¸ìš”:

ì˜í–¥ ê°€ì¤‘ì¹˜ (êµ¬ë§¤ ê²°ì • ìš”ì¸):
- ê°€ê²©: {weights.get('price', 25)}%
- ì£¼í–‰ê±°ë¦¬: {weights.get('range', 20)}%
- ì¶©ì „ ì¸í”„ë¼: {weights.get('charging_infrastructure', 15)}%
- ë¸Œëœë“œ ì‹ ë¢°: {weights.get('brand_trust', 12)}%
- í™˜ê²½ ì˜ì‹: {weights.get('environmental_concern', 10)}%

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì†Œë¹„ì í”„ë¡œí•„ (2-3ë¬¸ì¥)
2. ì£¼ìš” êµ¬ë§¤ ë™ê¸° (3ê°œ bullet points)
3. ë„ì… ì¥ë²½ (3ê°œ bullet points)
4. ë§ˆì¼€íŒ… ì‹œì‚¬ì  (2-3ë¬¸ì¥)
"""
            
            response = await self.llm.ainvoke(prompt)
            return response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            self.logger.error(f"ì¢…í•© ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "ì¢…í•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
    
    # Fallback ë°ì´í„°
    def _get_fallback_purchase_factors(self) -> Dict:
        return {
            'top_factors': ['ê°€ê²©', 'ì£¼í–‰ê±°ë¦¬', 'ì¶©ì „ í¸ì˜ì„±', 'ë¸Œëœë“œ ì‹ ë¢°ë„'],
            'note': 'Fallback ë°ì´í„°'
        }
    
    def _get_fallback_demographics(self) -> Dict:
        return {
            'age_groups': {
                '25-34': '35%',
                '35-44': '30%',
                '45-54': '20%',
                '55+': '15%'
            },
            'income_level': 'ì¤‘ìƒìœ„ì¸µ ì´ìƒ',
            'note': 'Fallback ë°ì´í„°'
        }
    
    def _get_fallback_price_sensitivity(self) -> Dict:
        return {
            'sensitivity_level': 'ë†’ìŒ',
            'acceptable_premium': '20-30% vs ë‚´ì—°ê¸°ê´€',
            'note': 'Fallback ë°ì´í„°'
        }
    
    def _get_fallback_brand_preferences(self) -> Dict:
        return {
            'top_brands': ['Tesla', 'Hyundai', 'Kia', 'Mercedes'],
            'loyalty_factors': ['ê¸°ìˆ ë ¥', 'ë¸Œëœë“œ ì´ë¯¸ì§€', 'A/S'],
            'note': 'Fallback ë°ì´í„°'
        }
    
    def _get_fallback_adoption_barriers(self) -> Dict:
        return {
            'barriers': [
                'ì¶©ì „ ì¸í”„ë¼ ë¶€ì¡±',
                'ë†’ì€ ì´ˆê¸° êµ¬ë§¤ ë¹„ìš©',
                'ì£¼í–‰ê±°ë¦¬ ë¶ˆì•ˆê°',
                'ì¶©ì „ ì‹œê°„'
            ],
            'note': 'Fallback ë°ì´í„°'
        }
    
    def _get_fallback_consumer_sentiment(self) -> Dict:
        return {
            'overall_sentiment': 'ê¸ì •ì  (70%)',
            'satisfaction_score': '4.2/5.0',
            'note': 'Fallback ë°ì´í„°'
        }